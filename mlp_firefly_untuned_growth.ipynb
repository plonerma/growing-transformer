{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurons selected by gradient magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sandbox import SimpleModel, toy_data, experiment_series, eval_series\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = (1, 1, 8, 2, 2)\n",
    "\n",
    "eps = 1e-4\n",
    "num_kept_neurons = 2\n",
    "lr=0.005\n",
    "runs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLP' object has no attribute '_new_neurons'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-10987448d7da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/Lab/firefly_transformer/growing_modules/sandbox.py\u001b[0m in \u001b[0;36mexperiment_series\u001b[0;34m(model_args, runs, **kw)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrowing_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"#{i}: loss: {result['loss_series'][-1]} - size: {result['size']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/Lab/firefly_transformer/growing_modules/sandbox.py\u001b[0m in \u001b[0;36mgrowing_train\u001b[0;34m(model, grow, lr, use_onecycle, num_batches, num_epochs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/Lab/firefly_transformer/growing_modules/sandbox.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/Lab/firefly_transformer/growing_modules/growing/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_neurons\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mold_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_features\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_new_neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLP' object has no attribute '_new_neurons'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def grow(model):\n",
    "    model.grow(num_novel=4, eps_novel=eps, eps_split=eps)\n",
    "    \n",
    "    with model.new_grad_only():\n",
    "        model.zero_grad()\n",
    "        \n",
    "        for _ in range(200): # batches\n",
    "            train_x, train_y = toy_data()\n",
    "            y = model(train_x)\n",
    "            loss = criterion(y, train_y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "        selected = model.select(num_kept_neurons)\n",
    "\n",
    "    model.degrow(*selected)\n",
    "\n",
    "series = experiment_series(model_params, runs=runs, grow=grow, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_series(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Path(\"results\")\n",
    "d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(series, d / 'firefly_random.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
