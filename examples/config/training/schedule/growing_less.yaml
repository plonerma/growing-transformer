training_epochs: 1

tune_params:
  direction:
    lr: 2e-3
  step_size:
    lr: 1e-3

growth_phase:
  - match: .encoder
    split: True
    num_novel: 0
    num_keep: 1
    tune_params: ${training.schedule.tune_params}
  - match: .mlp
    split: True
    num_novel: 128
    num_keep: 128
    tune_params: ${training.schedule.tune_params}
  - match: .attention.output
    # since there is no activation function bewtween the value and output layer
    # the split direction would just cancel out
    split: False
    num_novel: 8
    num_keep: 2
    tune_params: ${training.schedule.tune_params}
  - match: .dot_product
    split: False  # splitting up key and query is equivalent to just adding new neurons
    num_novel: 8
    num_keep: 2
    tune_params: ${training.schedule.tune_params}



steps:
  - lr_scheduler:
      type: linear
      warmup_portion: 0.06
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
  - grow: ${training.schedule.growth_phase}
  - train:
      num_epochs: ${training.schedule.training_epochs}
